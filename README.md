# Create-Openstack-using-Packstack
How to create openstack virtualization

1. Get UCS-C or any other servers configured with Storage Drives 
2. Add Virtual Media for Centos iso 
3. Create Virtual Drives
4. MAP CD/DVD, Load the Centos and Reboot
5. Loading and Configuring Centos on the Server

Once the server is ready, Pre-Config of all the servers - from KVM:
Set hostnames of the servers (don't need in all situation)
Assign IP with Tagged VLAN (needed)
Restart Network service 
If it fails, stop NetworkManager and try restart network again 
Ping and SSH from remote location:  

Pre-Config of all the servers - from KVM:
Set hostanmes of the servers (don't need in all situation)
hostnamectl set-hostname p-ctrl 
  
hostnamectl status
Assign IP with Tagged VLAN (needed)
[root@pack-comp03 network-scripts]# ll
total 248
-rw-r--r--. 1 root root    66 Aug 16 17:26 ifcfg-enp5s0
-rw-r--r--. 1 root root   161 Aug 16 17:31 ifcfg-enp5s0.2140
-rw-r--r--. 1 root root   311 Aug 16 17:07 ifcfg-enp6s0
  
[root@pack-comp03 network-scripts]# cat ifcfg-enp5s0
TYPE=Ethernet
BOOTPROTO=none
NAME=enp5s0
DEVICE=enp5s0
ONBOOT=yes
 
[root@pack-comp03 network-scripts]# cat ifcfg-enp5s0.2140
TYPE=Ethernet
BOOTPROTO=none
DEFROUTE=yes
IPADDR=10.5.131.128
PREFIX=24
GATEWAY=10.5.131.1
VLAN=yes
DNS1=10.0.1.1
NAME=enp5s0.2140
DEVICE=enp5s0.2140
ONBOOT=yes
Restart Network service 
systemctl restart network
If it fails, stop NetworkManager and try restart network again 
systemctl stop NetworkManager
systemctl disable NetworkManager
Ping and SSH from remote location:  

Packstack Install Process
On all the servers - controllers and computes:

Add hosts entry 
10.5.131.107 dc13-tb2-ctrl
10.5.131.108 dc13-tb2-comp08
10.5.131.109 dc13-tb2-comp09
10.5.131.110 dc13-tb2-comp10
10.5.131.111 dc13-tb2-comp11
10.5.131.112 dc13-tb2-comp12
Check resolv.conf for DNS
[root@dc13tb2-comp12 ~]# cat /etc/resolv.conf
# Generated by NetworkManager
nameserver 8.8.8.8
Check ping connectivity to google.com
[root@dc13tb2-comp12 ~]# ping google.com
PING google.com (172.217.2.174) 56(84) bytes of data.
64 bytes from yyz10s06-in-f14.1e100.net (172.217.2.174): icmp_seq=1 ttl=40 time=94.1 ms
64 bytes from yyz10s06-in-f14.1e100.net (172.217.2.174): icmp_seq=2 ttl=40 time=94.1 ms
64 bytes from yyz10s06-in-f14.1e100.net (172.217.2.174): icmp_seq=3 ttl=40 time=98.7 ms
^C
--- google.com ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2002ms
rtt min/avg/max/mdev = 94.119/95.654/98.703/2.184 ms
Only on Controller: Install Packages
yum install centos-release-openstack-mitaka -y    << Mitaka Release
or
yum install centos-release-openstack-newton -y    << Newton Release
  
Do this:
yum update -y
yum install openstack-packstack -y
  
====
Don't need to do these:
yum install https://rdoproject.org/repos/rdo-release.rpm -y    // dont do this or it will install Ocata
For Mitaka: https://repos.fedorapeople.org/repos/openstack/openstack-mitaka/rdo-release-mitaka-7.noarch.rpm -y
 

Only on Controller:  Answer File  working-packstack-answer-file-081717.txt, packstack-answer-file-cluster2.txt
packstack --answer-file=packstack-answer-file.txt
  
  
=====
[root@dc13-cluster2-ctrl11 ~]# packstack --answer-file=packstack-answer-file-cluster2.txt
Welcome to the Packstack setup utility
 
The installation log file is available at: /var/tmp/packstack/20171010-163354-E58YAB/openstack-setup.log
 
Installing:
Clean Up                                             [ DONE ]
Discovering ip protocol version                      [ DONE ]
Setting up ssh keys                                  [ DONE ]
Preparing servers                                    [ DONE ]
Pre installing Puppet and discovering hosts' details [ DONE ]
Preparing pre-install entries                        [ DONE ]
Installing time synchronization via NTP              [ DONE ]
Setting up CACERT                                    [ DONE ]
Preparing AMQP entries                               [ DONE ]
Preparing MariaDB entries                            [ DONE ]
Fixing Keystone LDAP config parameters to be undef if empty[ DONE ]
Preparing Keystone entries                           [ DONE ]
Preparing Glance entries                             [ DONE ]
Checking if the Cinder server has a cinder-volumes vg[ DONE ]
Preparing Cinder entries                             [ DONE ]
Preparing Nova API entries                           [ DONE ]
Creating ssh keys for Nova migration                 [ DONE ]
Gathering ssh host keys for Nova migration           [ DONE ]
Preparing Nova Compute entries                       [ DONE ]
Preparing Nova Scheduler entries                     [ DONE ]
Preparing Nova VNC Proxy entries                     [ DONE ]
Preparing OpenStack Network-related Nova entries     [ DONE ]
Preparing Nova Common entries                        [ DONE ]
Preparing Neutron LBaaS Agent entries                [ DONE ]
Preparing Neutron API entries                        [ DONE ]
Preparing Neutron L3 entries                         [ DONE ]
Preparing Neutron L2 Agent entries                   [ DONE ]
Preparing Neutron DHCP Agent entries                 [ DONE ]
Preparing Neutron Metering Agent entries             [ DONE ]
Checking if NetworkManager is enabled and running    [ DONE ]
Preparing OpenStack Client entries                   [ DONE ]
Preparing Horizon entries                            [ DONE ]
Preparing Swift builder entries                      [ DONE ]
Preparing Swift proxy entries                        [ DONE ]
Preparing Swift storage entries                      [ DONE ]
Preparing Puppet manifests                           [ DONE ]
Copying Puppet modules and manifests                 [ DONE ]
Applying 10.5.131.111_controller.pp
10.5.131.111_controller.pp:                          [ DONE ]
Applying 10.5.131.111_network.pp
10.5.131.111_network.pp:                             [ DONE ]
Applying 10.5.131.110_compute.pp
Applying 10.5.131.108_compute.pp
Applying 10.5.131.109_compute.pp
Applying 10.5.131.104_compute.pp
Applying 10.5.131.105_compute.pp
Applying 10.5.131.106_compute.pp
Applying 10.5.131.107_compute.pp
Applying 10.5.131.101_compute.pp
Applying 10.5.131.102_compute.pp
Applying 10.5.131.103_compute.pp
10.5.131.107_compute.pp:                             [ DONE ]
10.5.131.101_compute.pp:                             [ DONE ]
10.5.131.109_compute.pp:                             [ DONE ]
10.5.131.102_compute.pp:                             [ DONE ]
10.5.131.110_compute.pp:                             [ DONE ]
10.5.131.106_compute.pp:                             [ DONE ]
10.5.131.108_compute.pp:                             [ DONE ]
10.5.131.103_compute.pp:                             [ DONE ]
10.5.131.104_compute.pp:                             [ DONE ]
10.5.131.105_compute.pp:                             [ DONE ]
Applying Puppet manifests                            [ DONE ]
Finalizing                                           [ DONE ]
 
 **** Installation completed successfully ******

Make sure Openstack Dashboard is accessible
http://10.5.131.114/dashboard/project/instances/

 
Make sure OVS bridge exists, if not create it 
Refer to section: No Valid host found error in nova logs on this page 

Attach port to OVS bridge 
Refer to section: No Valid host found error in nova logs on this page 

Make sure you can create image in glance 
[root@p-ctrl14 images(keystone_admin)]# glance image-create --name CentOS-7.0-cloud-new.qcow2 --disk-format qcow2 --container-format bare --file CentOS-7.0-cloud-new.qcow2 --progress
[=============================>] 100%
+------------------+--------------------------------------+
| Property | Value |
+------------------+--------------------------------------+
| checksum | 6316f4f757e2dc870544d4111ee557f3 |
| container_format | bare |
| created_at | 2017-09-14T17:57:58Z |
| disk_format | qcow2 |
| id | cafc2013-8a61-4225-8462-b4e98de20f84 |
| min_disk | 0 |
| min_ram | 0 |
| name | CentOS-7.0-cloud-new.qcow2 |
| owner | 95d3a08a43e342bf8df3a1365848ea99 |
| protected | False |
| size | 1004994560 |
| status | active |
| tags | [] |
| updated_at | 2017-09-14T17:58:02Z |
| virtual_size | None |
| visibility | private |
+------------------+--------------------------------------+
Make sure you can create network 
[root@p-ctrl14 ~(keystone_admin)]# neutron net-list
+--------------------------------------+-----------+----------------------------------------------------+
| id | name | subnets |
+--------------------------------------+-----------+----------------------------------------------------+
| ef325090-df20-4d89-8abf-c7654e677037 | vlan-2144 | e7a36edc-c448-4252-a456-2da1a25cb5d2 10.5.135.0/24 |
+--------------------------------------+-----------+----------------------------------------------------+
[root@p-ctrl14 ~(keystone_admin)]# neutron subnet-list
+--------------------------------------+-------------+---------------+-------------------------------------------------+
| id | name | cidr | allocation_pools |
+--------------------------------------+-------------+---------------+-------------------------------------------------+
| e7a36edc-c448-4252-a456-2da1a25cb5d2 | 2144-subnet | 10.5.135.0/24 | {"start": "10.5.135.10", "end": "10.5.135.250"} |
+--------------------------------------+-------------+---------------+-------------------------------------------------+

Create availability zones 


Change Default Quota for Nova and Neutron
Nova Quoata Update


Neutron Quoata Update
 

[root@p-ctrl14 ~(keystone_admin)]# openstack project list
+----------------------------------+----------+
| ID | Name |
+----------------------------------+----------+
| 95d3a08a43e342bf8df3a1365848ea99 | admin |
| bfe516586c7c4af1b6aec0fd2ebebd41 | services |
+----------------------------------+----------+
[root@p-ctrl14 ~(keystone_admin)]#
[root@p-ctrl14 ~(keystone_admin)]# neutron quota-update --tenant-id 95d3a08a43e342bf8df3a1365848ea99 --network 100
[root@p-ctrl14 ~(keystone_admin)]# neutron quota-update --tenant-id 95d3a08a43e342bf8df3a1365848ea99 --subnet 200
[root@p-ctrl14 ~(keystone_admin)]# neutron quota-update --tenant-id 95d3a08a43e342bf8df3a1365848ea99 --port 2000
[root@p-ctrl14 ~(keystone_admin)]# neutron quota-update --tenant-id 95d3a08a43e342bf8df3a1365848ea99 --port 2000
+---------------------+-------+
| Field | Value |
+---------------------+-------+
| floatingip | 50 |
| network | 100 |
| port | 2000 |
| rbac_policy | 10 |
| router | 10 |
| security_group | 10 |
| security_group_rule | 100 |
| subnet | 200 |
| subnetpool | -1 |
+---------------------+-------+
 

Add Access & Security Rules


Launch VM
nova --debug boot --poll --flavor 79af137e-2b11-4c18-b4ba-0881fbe9d475 --image cafc2013-8a61-4225-8462-b4e98de20f84 --nic net-id=ef325090-df20-4d89-8abf-c7654e677037 TEST555 
  
TEST555 - name
  
Take TCP dump on control and compute to see whether the VM got an IP
[root@p-ctrl14 images(keystone_admin)]# tcpdump -i enp6s0 -n -e port 67
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on enp6s0, link-type EN10MB (Ethernet), capture size 262144 bytes
14:19:22.532577 fa:16:3e:3b:67:43 > Broadcast, ethertype 802.1Q (0x8100), length 346: vlan 2144, p 0, ethertype IPv4, 0.0.0.0.bootpc > 255.255.255.255.bootps: BOOTP/DHCP, Request from fa:16:3e:3b:67:43, length 300
14:19:22.550992 fa:16:3e:8a:1a:9a > fa:16:3e:3b:67:43, ethertype 802.1Q (0x8100), length 376: vlan 2144, p 0, ethertype IPv4, 10.5.135.10.bootps > 10.5.135.13.bootpc: BOOTP/DHCP, Reply, length 330
[root@p-comp16 network-scripts]# tcpdump -i enp6s0 -n -e port 67
tcpdump: WARNING: enp6s0: no IPv4 address assigned
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on enp6s0, link-type EN10MB (Ethernet), capture size 65535 bytes
14:19:22.532521 fa:16:3e:3b:67:43 > Broadcast, ethertype 802.1Q (0x8100), length 346: vlan 2144, p 0, ethertype IPv4, 0.0.0.0.bootpc > 255.255.255.255.bootps: BOOTP/DHCP, Request from fa:16:3e:3b:67:43, length 300
14:19:22.551052 fa:16:3e:8a:1a:9a > fa:16:3e:3b:67:43, ethertype 802.1Q (0x8100), length 376: vlan 2144, p 0, ethertype IPv4, 10.5.135.10.bootps > 10.5.135.13.bootpc: BOOTP/DHCP, Reply, length 330

Ping the VM IP from Outside 
[prabhjit.bagga@sjc-obs-linux18 ~]$ ping 10.5.135.12
PING 10.5.135.12 (10.5.135.12) 56(84) bytes of data.
64 bytes from 10.5.135.12: icmp_seq=61 ttl=60 time=1.33 ms
64 bytes from 10.5.135.12: icmp_seq=62 ttl=60 time=1.92 ms
Allow Password Authentication on - /etc/ssh/sshd_config  (From horizon VM console)
[root@host-10-5-135-12 ~]# cat /etc/ssh/sshd_config | grep PasswordAuth
#PasswordAuthentication yes
PasswordAuthentication yes
oot@host-10-5-135-12 ~]# service sshd restart
[prabhjit.bagga@sjc-obs-linux18 ~]$ ssh root@10.5.135.12
enter hostname:
root@10.5.135.12's password:
Last failed login: Thu Sep 14 20:21:06 UTC 2017 from 10.0.86.153 on ssh:notty
There was 1 failed login attempt since the last successful login.
Last login: Thu Sep 14 19:01:36 2017
[root@host-10-5-135-12 ~]#

Issues/workarounds
No Valid host found error in nova logs 
Check compute node if OVS bridge exists or not 
[root@p-comp04 ~]# ovs-vsctl show
3647a88c-06ab-4d0a-8e70-87dbd1626127
Bridge br-int
fail_mode: secure
Port br-int
Interface br-int
type: internal
ovs_version: "2.6.1"
  
// not present
Check interface config if birdge configs are present or not. If not add and restart networking! 
TYPE=Ethernet
BOOTPROTO=dhcp
DEFROUTE=yes
PEERDNS=yes
PEERROUTES=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_PEERDNS=yes
IPV6_PEERROUTES=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=enp7s0
UUID=d94e1299-b84d-48e7-895f-40266306d13c
DEVICE=enp7s0
ONBOOT=yes
DEVICETYPE=ovs         
TYPE=OVSPort           
OVS_BRIDGE=br-ex       
// add bottom 3 lines
If bridge not present add a new bridge, add ports, and list bridge 
ovs-vsctl add-br br-ex
ovs-vsctl add-port br-ex enp6s0
ovs-vsctl list-ports br-ex
enp6s0
phy-br-ex
Configure bridge mappings in openvswitch.ini config file 
[root@p-comp04 ~]# grep -v '^$\|^#' /etc/neutron/plugins/ml2/openvswitch_agent.ini
[DEFAULT]
[agent]
l2_population = False
drop_flows_on_start = False
[ovs]
integration_bridge = br-int
bridge_mappings =physnet1:br-ex                                                 // this line
enable_tunneling=False
[securitygroup]
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
Restart neutron services 
[root@p-comp19 ~]# cat neutron-restart.sh
tail -f /var/log/neutron/* &
service neutron-openvswitch-agent restart
ovs-vsctl list-ports br-enp7
  
output
[root@p-comp19 ~]# ovs-vsctl list-ports br-ex
enp6s0
phy-br-ex                   // this should be seen after restart
Launch VM again 


VM not getting IP 
DHCP request makes it out of compute node but not to the FI or switch or the controller 
Check if the VM is sending DHCP request with a tagged VLAN

[root@p-comp02 ~]# tcpdump -i enp7s0 -n -e port 67
tcpdump: WARNING: enp7s0: no IPv4 address assigned
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on enp7s0, link-type EN10MB (Ethernet), capture size 65535 bytes
19:25:47.678448 fa:16:3e:b5:4f:3e > Broadcast, ethertype 802.1Q (0x8100), length 346: vlan 3140, p 0, ethertype IPv4, 0.0.0.0.bootpc > 255.255.255.255.bootps: BOOTP/DHCP, Request from fa:16:3e:b5:4f:3e, length 300
19:25:50.557148 fa:16:3e:b5:4f:3e > Broadcast, ethertype 802.1Q (0x8100), length 346: vlan 3140, p 0, ethertype IPv4, 0.0.0.0.bootpc > 255.255.255.255.bootps: BOOTP/DHCP, Request from fa:16:3e:b5:4f:3e, length 300
19:25:53.275983 fa:16:3e:b5:4f:3e > Broadcast, ethertype 802.1Q (0x8100), length 346: vlan 3140, p 0, ethertype IPv4, 0.0.0.0.bootpc > 255.255.255.255.bootps: BOOTP/DHCP, Request from fa:16:3e:b5:4f:3e, length 300
Check if dhcp agent exists in horizon >Admin > Ntwork and it has an IP address 

Check if qdhcp exists on the controller node 

[root@p-ctrl ~(keystone_admin)]# ip netns
qdhcp-53900338-f105-444f-ac63-3bc504d3976a
qrouter-ca649d57-e49d-46e1-af29-70cd7ac1b248
qdhcp-1ac9754f-c4f0-45a7-9240-ecddb4499961

[root@p-ctrl ~(keystone_admin)]# neutron net-list
+--------------------------------------+---------------+-----------------------------------------------------+
| id | name | subnets |
+--------------------------------------+---------------+-----------------------------------------------------+
| 1ac9754f-c4f0-45a7-9240-ecddb4499961 | vlan-2142 | fadc48b8-fae6-4b00-a3d5-75498aa6c3ed 10.5.133.0/24 |
| 36c0dcf5-de82-419b-a73f-1baf70b0146e | internal-3142 | b8fcb588-abe1-4069-8626-3b9e9186dcab 192.168.2.0/24 |
| 53900338-f105-444f-ac63-3bc504d3976a | internal-3140 | 7abb0d6d-3220-4beb-a17c-dc1ff3e6711b 192.168.1.0/24 |
| 76a6d5ab-5d4c-48c8-a1db-bd02cccf788a | internal-3141 | |
+--------------------------------------+---------------+-----------------------------------------------------+

DHCP request makes it to the controller and DHCP agent but not out of it 
Restarts
Controller - Nova
 

Controller - Neutron
 

Compute - Nova
tail -f /var/log/nova/* &
echo 'service openstack-nova-compute restart'
service openstack-nova-compute restart
sleep 2
service openstack-nova-compute status
Compute - Neutron
tail -f /var/log/neutron/* &
service neutron-openvswitch-agent restart
sleep 2
service neutron-openvswitch-agent status
Create Golden Image 
To fix Time zone
Before
=======

qadc13-ost-001:/root# ll /etc/localtime
lrwxrwxrwx. 1 root root 25 Mar 31 2015 /etc/localtime -> ../usr/share/zoneinfo/UTC
qadc13-ost-001:/root# date
Tue Oct 24 20:53:30 UTC 2017
 

After
=======

qadc13-ost-001:/root# rm /etc/localtime
rm: remove symbolic link ‘/etc/localtime’? yes
qadc13-ost-001:/root# ln -s /usr/share/zoneinfo/America/Los_Angeles /etc/localtime      << for centos 7.2
qadc13-ost-001:/root# date
Tue Oct 24 13:53:41 PDT 2017
  
For centos 7.4
ln -s /usr/share/zoneinfo/US/Pacific /etc/localtime
 
ucs-22:/root# date
Wed Dec 20 14:15:54 PST 2017
 

 
To fix resolv.conf
 

qadc13-ost-001:/root# cat /etc/resolv.conf
; generated by /usr/sbin/dhclient-script
search i.jaspersystems.com jaspersystems.com
nameserver 10.41.0.254
nameserver 10.41.6.254
nameserver 10.0.1.35
chattr +i /etc/resolv.conf
 

 
Took a snapshot and created new golden-image called "qa-golden-image-time-zone-fix"

Saved it on sjc-obs-linux18 - /home/local/CORP/prabhjit.bagga/OPENSTACK/

Spawned a VM from it and verified that timezone and resolv.conf all in place !!
